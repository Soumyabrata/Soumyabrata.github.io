---
layout: page
permalink: /application/
title: Overview
tags: 
modified: 24-04-2017
comments: false
---
## Research Statement

The central theme of my research vision is to identify the specific computational problems in the above areas; and solve them in a cooperative manner with the domain experts. I am a firm believer of open science and research reproducibility â€“ and thereby interested to advance science by promoting mutual collaboration and collective efforts amongst the community. I am interested in developing computer-vision based techniques to analyze earth observations. Currently, I am also involved in applying deep-learning based techniques in consumer multimedia data. In the future, I am interested to extend my expertise of artificial intelligence in medical imaging, specifically, in multimodal neuroimaging.   

### Remote sensing
The future of solving energy crisis lies at the successful integration of solar and renewable energy into the conventional power grid. With the rapid development in photogrammetric techniques and low-cost weather station data, it is now increasingly easier to collect massive image and other meteorological sensor data of the earth's atmosphere from the ground. The key to many unsolved problems lies in systematically analyzing these massive data, and fusing these diverse data types to develop new tools and techniques in renewable energy. My research plan in this particular field of atmospheric observations lies at the intersection of remote sensing and machine learning. In particular, I am interested to visualize in what ways state-of-the-art techniques inspired from computer vision and machine learning community help us in analyzing solar energy falling at earth's surface.   

<br />
I am particularly interested to delve more into solar and renewable energy sectors. Currently, solar energy is the one of the most reliable sources of renewable energy. However, it suffers from two major drawbacks---variability and uncertainty. 
It is a well-known fact that clouds have a huge impact on this intermittency of Photovoltaic (PV) energy generation. The passage of clouds over the solar panels can incur variable fluctuations in the received solar irradiance on the earth's surface. This problem of intermittency can be effectively solved, if the cloud motion vectors can be accurately forecasted with a considerable lead time. An accurate forecast model will be highly beneficial for efficient solar energy generation. Such problems in remote sensing merit a more rigorous and thorough analysis in a multitude of applications, and I intend to bridge that gap. I am interested to study such remote-sensing problems from the perspective of computer vision and machine learning communities.   

<br />
My interest in this field of solar and renewable energy stems from my previous doctoral experience at Nanyang Technological University Singapore. My previous work involved the study and analysis of clouds in tropical regions, like Singapore, and to understand its impact in the signal attenuation of satellite communication links. We used ground-based sky cameras that continuously captures the images of the earth's atmosphere at regular intervals of time. These images are useful in generating a highly localized cloud profile.   


<img src="{{ site.baseurl }}/images/wsi-image.jpg">
*We designed low-cost, ground-based sky cameras for continuous cloud profiling. The region around the sun (popularly known as circumsolar region) is highlighted with a white rectangle.*   

<br />
These hardware developments in imaging the earth's atmosphere inspired me to analyze better the problems in solar energy generation and forecasting. These devices can provide a new paradigm in understanding the solar energy dynamics. I am interested to analyze how clouds can have an impact on the total solar irradiance falling on the earth's surface. This is an interesting problem at hand: how the intermittency and rapid fluctuations in solar radiation be best captured by ground-based imaging devices? This can be intuitively explained by the fact that a drop in total solar irradiance leads to a decreased imaging luminance by the camera sensor, and vice versa. With the massive amount of imaging data collected by such cameras, it will provide us a good user study to apply machine-learning techniques on such imaging data. I plan to use deep-learning based neural networks to parametrize the camera response curve of the imaging sensors. I am interested in modeling the received solar irradiance from the luminance of the sky camera. Additionally, I also plan to further miniaturize the sky cameras, so that it can be deployed at multiple locations across the region of interest. This will help us in mapping the entire solar irradiance map over the considered region.   

<br />
In summary, I am interested to work on this project on solar irradiance estimation and forecasting, as I firmly believe that efficient- and clear- energy generation is the need of the hour. Of course, solar energy encompasses a significant proportion of renewable energy. This project can be collaboratively executed alongside international institutions and research groups. I have already developed initial contacts with two leading solar energy forecasting group: Center for Energy Research, UC San Diego and Solar Energy Research Institute of Singapore (SERIS).   

### Multimedia Data

With the advancement in deep-learning techniques in image and video analysis, we have seen a massive interest in the field of autonomous driving from the leading companies in AI. There are a plethora of interesting problems in vision-based, computer-assisted self driving. However, I am interested to solve a specific problem in this area: to provide an end-to-end system in detecting the traffic- and road- signs from low-resolution car dashboard cameras. This problem becomes more challenging with poor lighting conditions during fog and misty weather conditions.   

<br />
My previous doctoral experience also dealt with using near-infrared cameras to see through fogs. Fredembach and Susstrunk demonstrated in their recent work that the haze disappears in near-infrared capture of an outdoor scene as compared to an image captured by a conventional RGB image. The following figure illustrates this. This is because of a physical phenomenon called Rayleigh scattering. Small atmospheric particles present in the air scatter incident light with varying degree. Because of Rayleigh scattering, the component of light having the least wavelength gets scattered the most; and thus provides a bluish color to the sky. However, near-infrared is less scattered as compared to its visible counterparts and renders the sky darker. I plan to investigate this characteristics of near-infrared imaging in the context of car dashboard cameras. Such imaging techniques are very important in our current application and has potential in capturing sharper and clearer images of the road scene. A regular RGB image, together with a near-infrared capture of the same scene will provide the car driver better insights about the traffic and road signs.    

<img src="{{ site.baseurl }}/images/haze-img.jpg">
*On the left, a conventional RGB image. On the right, a near-IR capture of the same scene. The haze has disappeared, revealing a sharper, cleaner, picture.*   

<br />
It is an interesting problem to harness the large amount of videos obtained from car dashboard cameras, with varying spectral resolutions. I am interested to use the color-information of the regular traffic signs to provide a robust and state-of-the-art object detection system. Color-based image segmentation is an expertise that I gathered since my PhD studies. During my doctoral problem, we presented a supervised segmentation framework for ground-based sky/cloud images based on a systematic analysis of different color spaces and components. Unlike other state-of-the-art cloud segmentation methods, our proposed approach was entirely learning-based and does not require any manually defined parameters. We also released a large segmentation database of annotated sky/cloud images, to the research community. Currently, at ADAPT Centre, Trinity College Dublin, I am also working on a segmentation-based task in an industry-affiliated project. I am investigating deep-learning based techniques to identify advertisement billboards in street-view videos. My current project is providing me the relevant know-hows for object detection and localization, in the field of vision-assisted autonomous driving.    

<br />
Apart from image-based data, I am also interested to explore other sensor data for assisted driving. I plan to use Light Detection and Ranging (LIDAR) data and Global Positioning System (GPS) for the same purpose. Such a multi-modal approach can help the driver to take an informed decision during autonomous navigation. I plan to execute this project with the assistance from small- and medium-size enterprises. I established contact with ai Robotics, an Anuva Ventures start-up company incubated in Singapore.    

<br />
In the future, I am interested to extend my expertise in image processing and machine learning in multimodal neuroimaging. Several studies have been conducted to study the amount of grey matter volume in the cortical and sub-cortical regions of the brain. This helps the medical experts in understanding chronic schizophrenia. I am interested in devising image-segmentation algorithms on MRI images to automatically calculate the global grey- and white- matter volume in the brain. I performed early experiments in this field, and intend to work further in developing image-based solutions.    

<br />
Inspired by the practical problems faced in various area, my vision is to use my expertise of machine learning and image processing to solve similar problems in myriad fields: solar energy, assisted driving and neuroimaging. Apart from my ongoing research, I am interested to continue involving myself in a number of education and outreach activities. Furthermore, I am a firm believer of open science, and the spirit of reproducible research. Therefore, whenever possible, I will continue to publish my preprints, and release the associated codes and datasets amongst the community.    